# Miscitations


## Bad Citations

* book: "when the same software developers were asked on two separate days to estimate the completion time for the same task, the hours they projected differed by 71%, on average." paper: "In this paper, we report from an experiment where seven experienced software professionals estimated the same sixty software development tasks over a period of three months. Six of the sixty tasks were estimated twice. We found a high degree of inconsistency in the software professionalsâ€™ effort estimates. The mean difference of the effort estimates of the same task by the same estimator was as much as 71%. The correlation between the corresponding estimates was 0.7." https://www.sciencedirect.com/science/article/abs/pii/S0164121207000714

* Hunger/Low blood glucose levels/etc.: "Our data consist of 1,112 judicial rulings, collected over 50 d in a 10-mo period, by eight Jewish-Israeli judges (two females) who preside over two different parole boards that serve four major prisons in Israel." https://www.pnas.org/doi/10.1073/pnas.1018033108#fig01 see also: http://journal.sjdm.org/16/16823/jdm16823.html

## Research Design

Problem: 

- Scientists rely on published research to create new research.
- They cite other research to support claims in service of creating new research.  
- Their interpretation of cited research is wrong in some cases.
- It remains unclear how often this occurs.

Research question: How often are citations to empirical claims incorrect?

Target population: Citations within articles published in the last 5 years in JAMA, NEJM, and Lancet

Sample: 100 randomly selected articles published in the last 5 years from each of JAMA, NEJM, and Lancet (300 total articles)

Method: 

1. randomly select 100 articles from each journal
2. define a coding protocol
3. test the coding protocol on 15 citations - one from the first 5 randomly selected articles from each of JAMA, NEJM, and Lancet
	- articles will be independently coded by 3 research assistants and two PIs
4. adjust coding protocol based on testing
5. test on 6 more citations - 2 from each journal - 3 research assistants
6. code remaining articles

additional notes: information about the randomly selected article and the citation will be extracted during the coding process


### Why do people do it?

* motivated reasoning
* lazy
* manipulative
* cannot tell the quality

### Coding

* How central is the citation to the claims in the paper?

* Quality of evidence ...
	* Empirical results vs. not [vs. anecdata vs. think pieces] - Was data collected or analyzed
	* Quality of empirical results
		* external validity
		* internal validity
		* replicability
		* size of the sample

* Qualifiers/limitations when people cite
	* correlation as causation
	* over-generalization: won't tell you about the context
	* make stronger claim than tenable 
		- strength of inference/statistical conclusion validity

### Minimum Sufficient Citation

* Minimum details: [n, context, research design]

* Counterfactual
	* Lay reader read this sentence what would they learn vs. when they read the paper
	* Responsibility of citee
		- Loss of information when we summarize is understandable but 
			- paper: key result + no contradicting result 
				- buy experimental design
				- n seems reasonable
